# Discussion Questions
-   For each area: What is the strongest motivation listed in the motivations section? The weakest? 
-   For each area: What is the strongest criticism in the criticisms section? The weakest? Why?
## Alignment
### Power-averseness
Strongest motivation = making it less likely for a single failure to cause existential catastrophe
Weakest motivation = permanently "disempower" humanity (since we could still be better off with the AI than not)

Strongest criticism = What military/entity wants to limit its power?
Weakest criticism = "Impossible" to overcome or counteract because power-seeking is instrumentally convergent.

### Honest AI
Strongest motivation = more chances for course-correction
Weakest motivation = "We would like to prevent models from producing deceptive information."  This seems loosely connected, and more like "accurate AI" than "honest AI".

Strongest criticism = current research uses contrived situations
Weakest criticism = "the truth is terrible".  So what?  The truth is usually better than falsehoods, and this doesn't mean that the AI will weaponize the truth.

### Implementing Moral Decision-Making
Strongest motiviation = Robustness is easiest to achieve in a limited area, and we want that area to be morality!
Weakest motivation = Slight misspecifications could create existential catastrophe without ethical objectives.  This argument could be applied to basically anything, and doesn't really explain why it's true.

Strongest criticism = Few ML researchers know normative ethics.
Weakest criticism = They're all really bad criticisms, but I think the one about "intimidating" technical researchers is the worst.

### Automated Moral Philosophy Research
Strongest motivation = more rapidly solve moral quandaries
Weakest motivation = "Locking in" values prematurely is bad.  (Why would we have to "lock in" our values?  A well-made artificial intelligence should listen when a group of people tell it to change its ways.)

Strongest criticism = (My own) An agent able to do research in moral philosophy is also intelligent enough to do research in other fields (e.g. math).  By this point, the alignment problem already needs to be solved more than any additional research into moral philosophy will help.
Weakest criticism = Nobody will trust the philosophy a machine gives them. (Way too strong a claim.)

## Monitoring
### Anomaly Detection
Strongest motivation = help flag for human review
Weakest motivation = detecting emergent behavior (unclear how this will be able to be detected by an anomaly detector)

Strongest criticism = Detecting a rogue model when it's virtually unstoppable is pointless.
Weakest criticism = When models are more intelligent, anomalies will be easy to detect.

### Interpretable Uncertainty
Strongest motivation = calibrated probabilities facilitate rational decision making.
Weakest motivation = They're all pretty strong motivations.

Strongest criticism = Doesn't directly reduce inherent hazards
Weakest criticism = We should only support work that has direct impact (linear causal influence)

### Trojan Horse Models
Strongest motivation = The most dangerous source of risk is unexpected changes in behavior when some conditions occur.
Weakest motivation = there was only one motivation.

Strongest criticism = 